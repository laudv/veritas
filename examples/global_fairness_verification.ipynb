{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62fea57b-cfdf-43d3-b811-be5c3f80782d",
   "metadata": {},
   "source": [
    "# Global Fairness Verification example\n",
    "\n",
    "Based on Calzavara et al. Explainable Global Fairness Veriﬁcation of Tree-Based Classiﬁers\" (2022).\n",
    "\n",
    "This example focuses on fairness that expresses (a lack of) causal discrimination. It is a global fairness (or verification of global robustness) task which means that is does not rely on the choice of a specific test set, but (implicitly) ranges over all possible instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227fe8d9-320e-4e4e-a156-830f0c8f46b0",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9f10ab-daaa-4e70-bb61-3dec404d21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc3f8b-21aa-45b8-a950-20efdb0c3a37",
   "metadata": {},
   "source": [
    "## German dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb5180-6551-43f8-b369-c4f6e0177686",
   "metadata": {},
   "source": [
    "We will use the [German Credit Data](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94fa0c-2399-4a7f-a460-61314d62cdad",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb318d6-9113-49f3-ba83-472a18f63d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = datasets.fetch_openml(data_id=31, return_X_y=True, as_frame=True)\n",
    "X, yn = datasets.fetch_openml(data_id=31, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523b787-b246-446f-9f5f-ec5b5e01a279",
   "metadata": {},
   "source": [
    "Make the target numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c561cd5-5d82-4127-ac3a-4c6f91ed37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (yn=='good').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f52c1-4b83-4186-855b-81f10173e7bd",
   "metadata": {},
   "source": [
    "We will focus on sex as a relevant parameter, thus will split up column 9 (index 8) 'personal_status'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0e0c8c-29e8-40fa-8a4e-39598a023cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird categories, so simplify to sex\n",
    "featmap = [0, 1, 0, 0, 1]\n",
    "X[:, 8] = [featmap[int(val)] for val in X[:, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e221d13-a20e-4357-a2f6-236d20f64676",
   "metadata": {},
   "source": [
    "Introduce bias: we can optionally introduce bias to make the effect easier to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "237137fe-3a95-4ccf-bee1-b6e5c2045a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "introduce_bias = 100\n",
    "if introduce_bias > 0:\n",
    "    X[0:introduce_bias, :] = X[0, :]\n",
    "    half_idx = int(introduce_bias/2)\n",
    "    X[:half_idx, 8] = 0\n",
    "    y[:half_idx] = 1\n",
    "    X[half_idx:introduce_bias, 8] = 1\n",
    "    y[half_idx:introduce_bias] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ca660-a037-4a89-a91b-969f6ddabb31",
   "metadata": {},
   "source": [
    "Use train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2bbd35-8240-4dc3-a82c-e48a8ea66f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest, ytrain_n, ytest_n = train_test_split(X, y, yn, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6ebb8-3d9a-4e56-a51b-c5ad9b63d31d",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75023e65-bc8d-444e-a324-4b43091e0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import veritas\n",
    "import xgboost as xgb\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb8f8d-9fe3-487f-a45e-eaa1abf27ea1",
   "metadata": {},
   "source": [
    "The original paper uses 12 trees of depth 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab71998-aae8-42bd-a39d-8a901dfcc7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB trained in 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 12 # 50\n",
    "params = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    #\"num_class\": 10,\n",
    "    #\"objective\": \"multi:softmax\",\n",
    "    #\"eval_metric\": \"merror\",\n",
    "    \"eval_metric\": \"error\",\n",
    "    \n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 135,\n",
    "    \"max_depth\": 6,  # 7,\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"colsample_bynode\": 0.75,\n",
    "    \"subsample\": 0.5\n",
    "}\n",
    "model = xgb.XGBClassifier(**params)\n",
    "\n",
    "t = time.time()\n",
    "model.fit(X, y)\n",
    "print(f\"XGB trained in {time.time()-t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698b2a65-d0af-438b-be01-6489ccff5531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.874, test acc: 0.850 wrt true labels\n"
     ]
    }
   ],
   "source": [
    "ytrain_pred = model.predict(xtrain)\n",
    "ytest_pred = model.predict(xtest)\n",
    "acc_train = accuracy_score(ytrain, ytrain_pred)\n",
    "acc_test = accuracy_score(ytest, ytest_pred)\n",
    "\n",
    "print(f\"Train acc: {acc_train:.3f}, test acc: {acc_test:.3f} wrt true labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047df41-4d14-421d-bc76-ae06067171e0",
   "metadata": {},
   "source": [
    "### Global fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a91d09-4996-4666-96d5-b6fd239cae4c",
   "metadata": {},
   "source": [
    "The features sex is considered sensitive. Who are the subset of people whose credit risk prediction does not change by ﬂipping their sex. This maps to a query where we want to contrast two instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f38cf-292a-4d15-952e-90e9a658ed9d",
   "metadata": {},
   "source": [
    "Start with loading the trained model, veritas figures out automatically it is a XGB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7a3376-924c-49eb-8dac-fbf1555c8436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_score according to XGB: 0.5\n",
      "base_score set to 0.0 if base_score was 0.5\n"
     ]
    }
   ],
   "source": [
    "at = veritas.get_addtree(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca69b3-5ead-4a24-8c00-5f1743cac4f8",
   "metadata": {},
   "source": [
    "For two instances X0 and X1, allowing only feature 9 (index 8) 'personal_status' to be different between the two instances, what is the maximum output difference at(X1)-at(X0)?\n",
    "The values that occur are 'male single', 'female div/dep/mar', 'male div/sep' and 'male mar/wid'. Thus only the 2nd (index 1) is female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a585481-598d-4245-b3f2-d60be0578d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_id used for personal_status for instances: 8 28\n"
     ]
    }
   ],
   "source": [
    "nonfixed_cols = {'personal_status'}\n",
    "feat_map = veritas.FeatMap(X_df.columns)\n",
    "for col in X_df.columns:\n",
    "    if col not in nonfixed_cols:\n",
    "        feat_map.use_same_id_for(feat_map.get_index(col, 0),\n",
    "                                 feat_map.get_index(col, 1))\n",
    "    else:\n",
    "        print(f\"feat_id used for {col} for instances:\",\n",
    "                feat_map.get_feat_id(col, 0),\n",
    "                feat_map.get_feat_id(col, 1))\n",
    "\n",
    "at_contrast = at.concat_negated(feat_map.transform(at, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "904645d2-4100-4782-95f5-8e7748018b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StopReason.OPTIMAL: 4>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = veritas.Config(veritas.HeuristicType.MAX_OUTPUT)\n",
    "s = config.get_search(at_contrast)\n",
    "duration = 10*60  # seconds\n",
    "save_steps = 10\n",
    "s.step_for(duration, save_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2206d114-9296-44f7-bd65-ec62a5b4c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum difference between instance0 and instance1\n",
      "- current best solution: 4.815625950000001 -> optimal solution\n",
      "- feature value ranges:\n",
      "           checking_status: Interval(<1)\n",
      "                  duration: Interval(<10)\n",
      "            credit_history: Interval(>=4)\n",
      "                   purpose: Interval(>=2)\n",
      "             credit_amount: Interval(866,1199)\n",
      "            savings_status: Interval(>=4)\n",
      "                employment: Interval(>=4)\n",
      "    installment_commitment: Interval(>=4)\n",
      "           personal_status: Interval(<1)\n",
      "             other_parties: Interval(<2)\n",
      "           residence_since: Interval(>=2)\n",
      "        property_magnitude: Interval(<1)\n",
      "                       age: Interval(>=67)\n",
      "       other_payment_plans: Interval(>=1)\n",
      "                   housing: Interval(1,2)\n",
      "            num_dependents: Interval(<2)\n",
      "             own_telephone: Interval(>=1)\n",
      "           personal_status: Interval(>=1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum difference between instance0 and instance1\")\n",
    "if s.num_solutions() > 0:\n",
    "    sol = s.get_solution(0)\n",
    "    print(\"- current best solution:\", sol.output, \"->\",\n",
    "          \"optimal\" if s.is_optimal() else \"suboptimal\", \"solution\")\n",
    "    # print(\"- feature value ranges\", sol.box())\n",
    "    print(\"- feature value ranges:\")\n",
    "    for key, interval in sol.box().items():\n",
    "        print(f\"  {feat_map.get_name(key):>24}: {interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b068924-936d-4c31-a4c7-616e17750891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non fixed column personal_status gets value 0.0\n",
      "Instance: [[  0.   9.   4.   2. 866.   4.   4.   4.   0.   1.   2.   0.  67.   1.\n",
      "    1.   0.   0.   1.   1.   0.]]\n",
      "==> Prediction is 1\n",
      "Non fixed column personal_status gets value 1.0\n",
      "Instance: [[  0.   9.   4.   2. 866.   4.   4.   4.   1.   1.   2.   0.  67.   1.\n",
      "    1.   0.   0.   1.   1.   0.]]\n",
      "==> Prediction is 0\n"
     ]
    }
   ],
   "source": [
    "new_instance = np.zeros((1, 20))\n",
    "for i in range(20):\n",
    "    if i in sol.box():\n",
    "        interval = sol.box()[i]\n",
    "        value = interval.hi - 1 if np.isinf(interval.lo) else interval.lo\n",
    "        new_instance[0,i] = value\n",
    "    else:\n",
    "        new_instance[0,i] = 0\n",
    "\n",
    "# new_instance = np.array([[0, 5, 4, 2, 1000, 4, 4, 4, pers_status, 1, 2, 0, 70, 1, 1, 0, 0, 0, 1, 0]])\n",
    "for col in nonfixed_cols:\n",
    "    for nb in (0, 1):\n",
    "        i = feat_map.get_feat_id(col, nb)\n",
    "        if i in sol.box():\n",
    "            interval = sol.box()[i]\n",
    "            value = interval.hi - 1 if np.isinf(interval.lo) else interval.lo\n",
    "            print(f\"Non fixed column {col} gets value {value}\")\n",
    "            i_mapped = X_df.columns.get_loc(col)\n",
    "            new_instance[0,i_mapped] = value\n",
    "        print(f\"Instance: {new_instance}\")\n",
    "        prediction = model.predict(new_instance)[0]\n",
    "        print(f\"==> Prediction is {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ecb30-7087-4bbe-b8c8-9e3b8d967f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
